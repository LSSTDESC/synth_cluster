{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7289d5c",
   "metadata": {},
   "source": [
    "# Synthetic Cluster Generation Tutorial Part 2: cluster  member emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d95b5",
   "metadata": {},
   "source": [
    "Owner: **Tamas Norbert Varga** @vargatn\n",
    "\n",
    "This notebook relies on one external package in addition to the default desc kernels on NERSC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074d7c0",
   "metadata": {},
   "source": [
    "This notebook will describe how to set up, run and postprocess the cluster line-of-sight emulation with the skysampler package. The settings are adapted to DC2 and DESC data products, see Part 1 of the tutorial.\n",
    "\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    * Load and collate galaxy catalogs \n",
    "    * Set up cluster line-of-sight emulation script\n",
    "    * INTENSIVE: Draw samples from the proposal galaxy catalog and calculate survival scores for rejection sampling.\n",
    "    * Define KDE model for cluster member galaxy features\n",
    "    * Visualize model against simulations\n",
    "\n",
    "Logistics: This notebook is intended to be be run with a python 3 installation of the skysampler package https://github.com/vargatn/skysampler/tree/lsst-dev  \n",
    "\n",
    "Other notes:\n",
    "\n",
    "    Some calculations in this notebook are time consuming, and are optimized for a HPC environment other than NERSC. These cells are currently commented out.\n",
    "    \n",
    "Output:\n",
    "\n",
    "    The results of this notebook are made available on NERSC at /global/cscratch1/sd/tvarga/DC_DATA/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecf05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio as fio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import subprocess as sp\n",
    "\n",
    "import scipy.interpolate as interpolate\n",
    "import pickle as pickle\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "# this package is installed from https://github.com/vargatn/skysampler/tree/lsst-dev  \n",
    "import skysampler.emulator as emulator\n",
    "import skysampler.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba02bc",
   "metadata": {},
   "source": [
    " # Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04263fec",
   "metadata": {},
   "source": [
    "## Concatenate cluster catalog cutouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9b6e6",
   "metadata": {},
   "source": [
    "We are concatenating the galaxy catalog cutouts around clusters. These are initially saved in a separate file for each cluster. For further processing these are saved again in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c97daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_hdf(\"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/cosmoDC2_v1.1.4_redmapper_v0.7.5_clust.h5\", key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d401e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = (clusters[\"richness\"] > 30) & (clusters[\"richness\"] < 60) & (clusters[\"redshift\"] > 0.3) & (clusters[\"redshift\"] < 0.35)\n",
    "ii.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a6d37",
   "metadata": {},
   "source": [
    "Note that above we restricts the redshift range to 0.3 - 0.35. This is done as the emulated clusters will be representative of the ensemble properties of the selection. A narrow redshift range minimizes the intrinsic spread in apparent photometry properties.\n",
    "\n",
    "There are 41 clusters in this selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46988736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = []\n",
    "# for cid in clusters[ii][\"cluster_id\"]:\n",
    "#     print(cid)\n",
    "#     fname = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/clust-{}_dc2-sim-cutout.h5\".format(cid)\n",
    "#     tab = pd.read_hdf(fname, key=\"data\")\n",
    "#     tab[\"cluster_id\"] = cid\n",
    "#     tab = tab[tab[\"R\"] < 16 ]\n",
    "#     table.append(tab)\n",
    "# table = pd.concat(table)\n",
    "# oname = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/clust_dc2-sim-LOS_v1.h5\"\n",
    "# table.to_hdf(oname, key=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d4cef",
   "metadata": {},
   "source": [
    "## reference field data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1fab2",
   "metadata": {},
   "source": [
    "Since we saved all galaxies from three randomly selected healpix pixels, we are now concatenating them for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = [8786, 8791, 9937]\n",
    "refpixel = []\n",
    "for pix in pixels:\n",
    "    print(pix)\n",
    "    tmp = pd.read_hdf(\"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/cosmoDC2_v1.1.4_refpixel-{}.h5\".format(pix), key=\"data\")\n",
    "    refpixel.append(tmp)\n",
    "refpixel = pd.concat(refpixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37edd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "refpixel[\"R\"] = np.sqrt(np.random.uniform(0, 16**2., size=len(refpixel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6503d3b",
   "metadata": {},
   "source": [
    "We assign a mock uniform radial profile to reference field galaxies. In case of availability, this can be replaced by the radial profile around random points (such as redmapper randoms). That approach is bit more advanced, and captures the un-evennes and edges in the survey footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refpixel.to_hdf(\"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/cosmoDC2_v1.1.4_refpixels.h5\", key=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312a2dc",
   "metadata": {},
   "source": [
    "# Train KDE model and calculate survival scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16708b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_root = \"dc2-alpha_concentric_sample-v01_test-03\" # this is what the current output files will be saved as\n",
    "NREPEATS = 4 # number of times the full run is repeated\n",
    "NSAMPLES = 1600000 # number of propsal samples to draw\n",
    "NCHUNKS = 160 # number of CPU cores to use\n",
    "bandwidth=0.1 # Gaussian KDE bandwidth in the eigen-feature space after applying PCA\n",
    "\n",
    "# data paths, the code will create a subfolder within root_path based on tag_root\n",
    "root_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/resamples/\"\n",
    "deep_data_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/cosmoDC2_v1.1.4_refpixels.h5\"\n",
    "wide_data_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/clust_dc2-sim-LOS_v1.h5\"\n",
    "\n",
    "# The number of galaxies goes with surface area element, to avoid modeling very un-balanced PDFs \n",
    "# a series of nested concentric segments are modeled consecutively and later stiched together\n",
    "LOGR_DRAW_RMINS = np.array([-3, -0.5, 0., 0.5])\n",
    "LOGR_DRAW_RMAXS = np.array([-0.5, 0., 0.5, 1.2])\n",
    "LOGR_CAT_RMAXS = [0., 0.5, 1.1, 1.2]\n",
    "\n",
    "# feature aliases and definitions from the deep / reference dataset for comparison with the wide dataset\n",
    "deep_c_settings = {\n",
    "    \"columns\": [\n",
    "        (\"MAG_I\", \"mag_i\"),\n",
    "        (\"COLOR_G_R\", (\"mag_g\", \"mag_r\", \"-\")),\n",
    "        (\"COLOR_R_I\", (\"mag_r\", \"mag_i\", \"-\")),\n",
    "    ],\n",
    "    \"logs\": [False, False, False, False],\n",
    "    \"limits\": [(17, 22.5), (-1, 3), (-1, 3), (-1, 3)],\n",
    "}\n",
    "\n",
    "# feature aliases and definitions for all features we want to model and inherit from the deep / reference fields\n",
    "deep_smc_settings = {\n",
    "    \"columns\": [\n",
    "        (\"GABS\", (\"ellipticity_1_true\", \"ellipticity_2_true\", \"SQSUM\")),\n",
    "        (\"SIZE\", \"size_true\"),\n",
    "        (\"MAG_I\", \"mag_i\"),\n",
    "        (\"COLOR_G_R\", (\"mag_g\", \"mag_r\", \"-\")),\n",
    "        (\"COLOR_R_I\", (\"mag_r\", \"mag_i\", \"-\")),\n",
    "        (\"COLOR_I_Z\", (\"mag_i\", \"mag_z\", \"-\")),\n",
    "        (\"STELLAR_MASS\", \"stellar_mass\"),\n",
    "        (\"HALO_MASS\", \"halo_mass\")\n",
    "    ],\n",
    "    \"logs\": [False, True, False, False, False, False, True, True],\n",
    "    \"limits\": [(0., 1.), (-1, 5), (17, 25), (-1, 3), (-1, 3), (-1, 3), (10**3, 10**13), (10**9, 10**16)],\n",
    "}\n",
    "\n",
    "# feature aliases and definitions from wide dataset\n",
    "wide_cr_settings = {\n",
    "    \"columns\": [\n",
    "        (\"MAG_I\", \"mag_i\"),\n",
    "        (\"COLOR_G_R\", (\"mag_g\", \"mag_r\", \"-\")),\n",
    "        (\"COLOR_R_I\", (\"mag_r\", \"mag_i\", \"-\")),\n",
    "        (\"LOGR\", \"R\"),\n",
    "    ],\n",
    "    \"logs\": [False, False, False, True],\n",
    "    \"limits\": [(17, 22.5), (-1, 3), (-1, 3), (1e-3, 16.), ],\n",
    "}\n",
    "\n",
    "# the radial profile around clusters from the wide dataset\n",
    "wide_r_settings = {\n",
    "    \"columns\": [\n",
    "        (\"MAG_I\", \"mag_i\"),\n",
    "        (\"LOGR\", \"R\"),\n",
    "    ],\n",
    "    \"logs\": [False, True,],\n",
    "    \"limits\": [(17, 22.5), (1e-3, 16.),],\n",
    "}\n",
    "# features to use for rejection sampling\n",
    "columns = {\n",
    "    \"cols_dc\": [\"COLOR_G_R\", \"COLOR_R_I\",],\n",
    "    \"cols_wr\": [\"LOGR\",],\n",
    "    \"cols_wcr\": [\"COLOR_G_R\", \"COLOR_R_I\", \"LOGR\",],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65c1eb",
   "metadata": {},
   "source": [
    "The below script carries out most heavy lifting calculation\n",
    "\n",
    "1) loading the data\n",
    "\n",
    "2) constructs the features from the above dictionaries\n",
    "\n",
    "3) transforms features into their eigien-space and builds a KDE\n",
    "\n",
    "4) draws NSAMPLES proposal points from the features in  deep_smc_settings \n",
    "\n",
    "5) scores each proposal point based on the KDE models of the other features. (scores are transformed according to PCA jacobian for each feature space)\n",
    "\n",
    "6) saves samples, scores, and jacobian for each draw\n",
    "\n",
    "This section is commented out as it takes a ~few hunderd CPU hours to run and it's not optimized for NERSC job managers. Currently it was ran in a local computing resource at LMU Munich.\n",
    "\n",
    "The results of the calculation are made available on NERSC, so feel free to skip to the next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"started reading\")\n",
    "# refpixel = pd.read_hdf(deep_data_path, key=\"data\")\n",
    "# table = pd.read_hdf(wide_data_path, key=\"data\")\n",
    "\n",
    "# print(\"creating output folder\")\n",
    "# root_path = root_path + tag_root + \"/\"\n",
    "# print(root_path)\n",
    "# if not os.path.isdir(root_path):\n",
    "#     os.mkdir(root_path)\n",
    "\n",
    "# nrbins = len(LOGR_DRAW_RMINS)\n",
    "# print(\"NRBINS:\", nrbins)\n",
    "\n",
    "# for nrep in np.arange(NREPEATS):\n",
    "#     tag = tag_root + \"_run\" + str(nrep)\n",
    "#     print(\"running repeat\", nrep, \"out of\", NREPEATS)\n",
    "#     print(tag)\n",
    "\n",
    "#     master_seed = np.random.randint(0, np.iinfo(np.int32).max, 1)[0]\n",
    "#     rng = np.random.RandomState(seed=master_seed)\n",
    "#     seeds = rng.randint(0, np.iinfo(np.int32).max, nrbins * 5)\n",
    "\n",
    "#     i = 0\n",
    "#     print(\"starting concentric shell resampling\")\n",
    "#     for i in np.arange(nrbins):\n",
    "#         print(\"rbin\", i)\n",
    "#         outname = root_path + \"/\" + tag + \"_{:1d}\".format(master_seed) + \"_rbin{:d}\".format(i)\n",
    "#         print(outname)\n",
    "\n",
    "#         # loading random data\n",
    "#         tmp_wide_r_settings = wide_r_settings.copy()\n",
    "#         tmp_wide_r_settings[\"limits\"][-1] = (10**-3, 10**LOGR_CAT_RMAXS[i])\n",
    "#         _wide_r_settings_rands = emulator.construct_deep_container(refpixel, tmp_wide_r_settings, seed=seeds[nrbins * i + 0], drop=\"MAG_I\")\n",
    "\n",
    "#         tmp_wide_cr_settings = wide_cr_settings.copy()\n",
    "#         tmp_wide_cr_settings[\"limits\"][-1] = (10**-3, 10**LOGR_CAT_RMAXS[i])\n",
    "#         _wide_cr_settings_rands = emulator.construct_deep_container(refpixel, tmp_wide_cr_settings, seed=seeds[nrbins * i + 1], drop=\"MAG_I\")\n",
    "\n",
    "#         # loading deep catalogs\n",
    "#         _deep_c_settings = emulator.construct_deep_container(refpixel, deep_c_settings, seed=seeds[nrbins * i + 2], drop=\"MAG_I\")\n",
    "#         _deep_smc_settings = emulator.construct_deep_container(refpixel, deep_smc_settings, seed=seeds[nrbins * i + 3])\n",
    "\n",
    "#         # loading cluster data\n",
    "#         tmp_wide_cr_settings = wide_cr_settings.copy()\n",
    "#         tmp_wide_cr_settings[\"limits\"][-1] = (10**-3, 10**LOGR_CAT_RMAXS[i])\n",
    "#         _wide_cr_settings_clust = emulator.construct_deep_container(table, tmp_wide_cr_settings, seed=seeds[nrbins * i + 4], drop=\"MAG_I\")\n",
    "\n",
    "#         infodicts, samples = emulator.make_classifier_infodicts(_wide_cr_settings_clust, _wide_r_settings_rands,\n",
    "#                                                                 _wide_cr_settings_rands,\n",
    "#                                                                 _deep_c_settings, _deep_smc_settings,\n",
    "#                                                                 columns, nsamples=NSAMPLES, nchunks=NCHUNKS,\n",
    "#                                                                 bandwidth=bandwidth,\n",
    "#                                                                 rmin=LOGR_DRAW_RMINS[i],\n",
    "#                                                                 rmax=LOGR_DRAW_RMAXS[i])\n",
    "\n",
    "#         fname = outname + \"_samples.fits\"\n",
    "#         print(fname)\n",
    "#         fio.write(fname, samples.to_records(), clobber=True)\n",
    "#         master_dict = {\n",
    "#             \"columns\": infodicts[0][\"columns\"],\n",
    "#             \"bandwidth\": infodicts[0][\"bandwidth\"],\n",
    "#             \"deep_c_settings\": deep_c_settings,\n",
    "#             \"deep_smc_settings\": deep_smc_settings,\n",
    "#             \"wide_r_settings\": tmp_wide_r_settings,\n",
    "#             \"wide_cr_settings\": tmp_wide_cr_settings,\n",
    "#             \"rmin\": infodicts[0][\"rmin\"],\n",
    "#             \"rmax\": infodicts[0][\"rmin\"],\n",
    "#         }\n",
    "#         pickle.dump(master_dict, open(outname + \".p\", \"wb\"))\n",
    "#         print(\"calculating scores\")\n",
    "#         result = emulator.run_scores2(infodicts)\n",
    "#         print(\"finished calculating scores\")\n",
    "#         fname = outname + \"_scores.fits\"\n",
    "#         print(fname)\n",
    "#         fio.write(fname, result.to_records(), clobber=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a2706",
   "metadata": {},
   "source": [
    "# Posprocess  rejection sampling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1056dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_reader2(samples, scores, m_factor=20, nratio=1., seed=None):\n",
    "    \"\"\"\n",
    "    Calculate the index of accepted proposal draws based on the scores and jacobians calcualted above\n",
    "    \"\"\"\n",
    "    dc_score = np.exp(scores[\"dc\"]) * np.abs(scores[\"dc_jac\"])\n",
    "    wr_score = np.exp(scores[\"wr\"]) * np.abs(scores[\"wr_jac\"])\n",
    "    wcr_clust_score = np.exp(scores[\"wcr_clust\"]) * np.abs(scores[\"wcr_clust_jac\"])\n",
    "    wcr_rands_score = np.exp(scores[\"wcr_rands\"]) * np.abs(scores[\"wcr_rands_jac\"])\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    uniform = rng.uniform(0, 1, len(samples)) \n",
    "    \n",
    "    p_proposal = m_factor * dc_score * wr_score\n",
    "    p_rands_ref = wcr_rands_score\n",
    "    p_clust_ref = wcr_clust_score \n",
    "    print(nratio)\n",
    "    inds_field = (uniform < (p_rands_ref / nratio / p_proposal))\n",
    "    inds_clust = ((p_rands_ref / nratio / p_proposal) < uniform) * (uniform < (p_clust_ref  / p_proposal))\n",
    "    inds_2d = ((uniform < (p_clust_ref  / p_proposal)))\n",
    "\n",
    "    return inds_field, inds_clust, inds_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a67164",
   "metadata": {},
   "source": [
    "The below settings are mostly identical to the previous section.\n",
    "\n",
    "Since we are working in DC2, we have access to all features in the deep / reference data also around clusters, so we modify that feature list to include everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_root = \"dc2-alpha_concentric_sample-v01_test-03\"\n",
    "NREPEATS = 4\n",
    "NSAMPLES = 1600000\n",
    "NCHUNKS = 160\n",
    "bandwidth=0.1\n",
    "\n",
    "root_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/resamples/\"\n",
    "deep_data_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/cosmoDC2_v1.1.4_refpixels.h5\"\n",
    "wide_data_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/clust_dc2-sim-LOS_v1.h5\"\n",
    "\n",
    "LOGR_DRAW_RMINS = np.array([-3, -0.5, 0., 0.5])\n",
    "LOGR_DRAW_RMAXS = np.array([-0.5, 0., 0.5, 1.2])\n",
    "LOGR_CAT_RMAXS = [0., 0.5, 1.1, 1.2]\n",
    "\n",
    "deep_smc_settings = {\n",
    "    \"columns\": [\n",
    "        (\"GABS\", (\"ellipticity_1_true\", \"ellipticity_2_true\", \"SQSUM\")),\n",
    "        (\"SIZE\", \"size_true\"),\n",
    "        (\"MAG_I\", \"mag_i\"),\n",
    "        (\"COLOR_G_R\", (\"mag_g\", \"mag_r\", \"-\")),\n",
    "        (\"COLOR_R_I\", (\"mag_r\", \"mag_i\", \"-\")),\n",
    "        (\"COLOR_I_Z\", (\"mag_i\", \"mag_z\", \"-\")),\n",
    "        (\"STELLAR_MASS\", \"stellar_mass\"),\n",
    "        (\"HALO_MASS\", \"halo_mass\")        \n",
    "    ],\n",
    "    \"logs\": [False, True, False, False, False, False, True, True],\n",
    "    \"limits\": [(0., 1.), (-1, 5), (17, 25), (-1, 3), (-1, 3), (-1, 3), (10**3, 10**13), (10**9, 10**16)],\n",
    "}\n",
    "\n",
    "# this is just a copy of the deep_smc_settings, in DC2 we have access to this information\n",
    "wide_cr_settings = {\n",
    "    \"columns\": [\n",
    "        (\"GABS\", (\"ellipticity_1_true\", \"ellipticity_2_true\", \"SQSUM\")),\n",
    "        (\"SIZE\", \"size_true\"),\n",
    "        (\"MAG_I\", \"mag_i\"),\n",
    "        (\"COLOR_G_R\", (\"mag_g\", \"mag_r\", \"-\")),\n",
    "        (\"COLOR_R_I\", (\"mag_r\", \"mag_i\", \"-\")),\n",
    "        (\"COLOR_I_Z\", (\"mag_i\", \"mag_z\", \"-\")),\n",
    "        (\"STELLAR_MASS\", \"stellar_mass\"),\n",
    "        (\"HALO_MASS\", \"halo_mass\"),\n",
    "        (\"LOGR\", \"R\"),        \n",
    "    ],\n",
    "    \"logs\": [False, True, False, False, False, False, True, True, True],\n",
    "    \"limits\": [(0., 1.), (-1, 5), (17, 25), (-1, 3), (-1, 3), (-1, 3), (10**3, 10**13), (10**9, 10**16), (1e-3, 16)],\n",
    "}\n",
    "\n",
    "columns = {\n",
    "    \"cols_dc\": [\"COLOR_G_R\", \"COLOR_R_I\",],\n",
    "    \"cols_wr\": [\"LOGR\",],\n",
    "    \"cols_wcr\": [\"COLOR_G_R\", \"COLOR_R_I\", \"LOGR\",],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf831c3",
   "metadata": {},
   "source": [
    " loading a bunch of data files, this part is a bit redundant, but if you did not execute the previous section then you have to load them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_data_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/cosmoDC2_v1.1.4_refpixels.h5\"\n",
    "wide_data_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/dc2_cluster_sim_cutouts/clust_dc2-sim-LOS_v1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "refpixel = pd.read_hdf(deep_data_path, key=\"data\")\n",
    "table = pd.read_hdf(wide_data_path, key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_wide_cr_settings = wide_cr_settings.copy()\n",
    "# tmp_wide_cr_settings[\"limits\"][-1] = (10**-3, 10**LOGR_CAT_RMAXS[i])\n",
    "_wide_cr_settings_rands = emulator.construct_deep_container(refpixel, tmp_wide_cr_settings)\n",
    "\n",
    "# loading deep catalogs\n",
    "_deep_smc_settings = emulator.construct_deep_container(refpixel, deep_smc_settings)\n",
    "\n",
    "# loading cluster data\n",
    "tmp_wide_cr_settings = wide_cr_settings.copy()\n",
    "# tmp_wide_cr_settings[\"limits\"][-1] = (10**-3, 10**LOGR_CAT_RMAXS[i])\n",
    "_wide_cr_settings_clust = emulator.construct_deep_container(table, tmp_wide_cr_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0bf6e",
   "metadata": {},
   "source": [
    "Loop over the files which contain the proposed galaxy draws, and the corresponding acceptance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "scores = []\n",
    "for rbin in np.arange(4):\n",
    "    print(rbin)\n",
    "#     expr = \"/e/ocean1/users/vargatn/EMULATOR/EPSILON/resamples/epsilon_concentric_sample_v06_run*_rbin\" + str(rbin) + \"*samples.fits\" \n",
    "    expr = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/clusters_v01/resamples/dc2-alpha_concentric_sample-v01_test-03/dc2-alpha_concentric_sample-v01_test-03_run0*_rbin\" + str(rbin) + \"*samples.fits\" \n",
    "\n",
    "    fnames_samples = np.sort(glob.glob(expr))\n",
    "    fnames_scores = []\n",
    "    for fname in fnames_samples:\n",
    "        fnames_scores.append(fname.replace(\"samples.fits\", \"scores.fits\"))\n",
    "\n",
    "    samples_sep = []\n",
    "    scores_sep = []\n",
    "    for i, fname in enumerate(fnames_samples):\n",
    "#         print(fname)\n",
    "        samples_sep.append(fio.read(fname))\n",
    "        scores_sep.append(fio.read(fnames_scores[i]))\n",
    "        \n",
    "    samples.append(np.hstack(samples_sep))\n",
    "    scores.append(np.hstack(scores_sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb9f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed surface density of **bright** fields galaxies, \n",
    "# this will anchor our expectation about the full galaxy distribution\n",
    "\n",
    "magcol = \"mag_i\"\n",
    "ii = ((table[magcol] > mag_lims[0]) & (table[magcol] < mag_lims[1]))\n",
    "\n",
    "clust_los_nums = np.histogram(np.log10(table[ii][\"R\"]), bins=redges)[0] / 41 # / nc\n",
    "\n",
    "ii = ((refpixel[magcol] > mag_lims[0]) & (refpixel[magcol] < mag_lims[1]))\n",
    "surfdens = len(refpixel[ii]) / hp.nside2pixarea(32, degrees=True) / 3600 / 3\n",
    "rands_los_nums = surfdens * rareas\n",
    "# rands_los_nums = np.histogram(np.log10(refpixel[ii][\"R\"]), bins=redges)[0] / rareas#* ratio# / nr\n",
    "nratios = clust_los_nums / rands_los_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc03270",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifields2 = []\n",
    "iclusts2 = []\n",
    "i2ds2 = []\n",
    "for rbin in np.arange(4):\n",
    "    print(rbin)\n",
    "    _ifield, _iclust, _i2d = result_reader2(samples[rbin], scores[rbin], nratio=nratios[rbin], m_factor=100, seed=rbin)\n",
    "    ifields2.append(_ifield)\n",
    "    iclusts2.append(_iclust)\n",
    "    i2ds2.append(_i2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea60a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a mock galaxy sample representative of cluster member galaxies\n",
    "csamples = []\n",
    "for rbin in np.arange(4):\n",
    "    print(rbin)\n",
    "    tab = pd.DataFrame.from_records(samples[rbin][iclusts2[rbin]].byteswap().newbyteorder())\n",
    "    tab.drop('index', axis=1, inplace=True)\n",
    "    kde = emulator.KDEContainer(tab)\n",
    "    kde.standardize_data()\n",
    "    kde.construct_kde(0.1)\n",
    "    _csample = kde.random_draw(4e6)\n",
    "    csamples.append(_csample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca84d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a mock galaxy sample representative of field galaxies, this is a good sanity check to compare with the reference fields\n",
    "rsamples = []\n",
    "for rbin in np.arange(4):\n",
    "    print(rbin)\n",
    "    tab = pd.DataFrame.from_records(samples[rbin][ifields2[rbin]].byteswap().newbyteorder())\n",
    "    tab.drop('index', axis=1, inplace=True)\n",
    "    kde = emulator.KDEContainer(tab)\n",
    "    kde.standardize_data()\n",
    "    kde.construct_kde(0.1)\n",
    "    _rsample = kde.random_draw(4e6)\n",
    "    rsamples.append(_rsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e66456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a mock galaxy sample representative of all galaxies in the cluster line of sight. This is a mixture of cluster member and non-cluster member galaxies\n",
    "allsamples = []\n",
    "for rbin in np.arange(4):\n",
    "    print(rbin)\n",
    "    tab = pd.DataFrame.from_records(samples[rbin][i2ds2[rbin]].byteswap().newbyteorder())\n",
    "    tab.drop('index', axis=1, inplace=True)\n",
    "    kde = emulator.KDEContainer(tab)\n",
    "    kde.standardize_data()\n",
    "    kde.construct_kde(0.1)\n",
    "    _sample = kde.random_draw(4e6)\n",
    "    allsamples.append(_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4e539",
   "metadata": {},
   "source": [
    "## Visualize model and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905f8ee",
   "metadata": {},
   "source": [
    "Let's visualize what the above cluster line of sight models predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tohist(edges, vals):\n",
    "    arr = []\n",
    "    res = []\n",
    "    for i in np.arange(len(vals)):\n",
    "        arr.append(edges[i])\n",
    "        arr.append(edges[i + 1])\n",
    "        res.append(vals[i])\n",
    "        res.append(vals[i])\n",
    "    return arr, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65852afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(nrows=3, ncols=4, figsize=(11.5, 7.), sharex=False, sharey=False)\n",
    "fig.subplots_adjust(hspace=0.075, wspace=0.05)\n",
    "\n",
    "bins_hist = np.linspace(-0.5, 2.5, 20)\n",
    "cens_hist = bins_hist[:-1] + np.diff(bins_hist) / 2\n",
    "bins_kde = np.linspace(-0.5, 2.5, 40)\n",
    "cens = bins_kde[:-1] + np.diff(bins_kde) / 2\n",
    "\n",
    "for ax in axarr[0]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in axarr[1]:\n",
    "    ax.set_xticklabels([])    \n",
    "\n",
    "for ax in axarr[:, 0]:\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "for ax in axarr[0, 1:]:\n",
    "    ax.set_yticklabels([])\n",
    "for ax in axarr[1, 1:]:\n",
    "    ax.set_yticklabels([])\n",
    "for ax in axarr[2, 1:]:\n",
    "    ax.set_yticklabels([])    \n",
    "        \n",
    "for ax in axarr[2]:\n",
    "    ax.set_xlabel(\"g - r\", fontsize=12)\n",
    "for ax in axarr[:, 0]:\n",
    "    ax.set_ylabel(\"p.d.f.\", fontsize=12)\n",
    "    \n",
    "col = \"COLOR_G_R\" \n",
    "magcol = \"MAG_I\"\n",
    "rcol = \"LOGR\"\n",
    "\n",
    "r_lims_all = [(-1.5, -0.5), (-0.5, 0.), (0, 0.5), (0.5, 1.0)]\n",
    "\n",
    "# ####################################################################################################\n",
    "mag_lims = (19., 21.)\n",
    "for rbin in np.arange(4):\n",
    "    ax = axarr[0, rbin]\n",
    "\n",
    "    r_lims = r_lims_all[rbin]\n",
    "    sample = samples[rbin]\n",
    "    csample = csamples[rbin]\n",
    "    rsample = rsamples[rbin]\n",
    "\n",
    "\n",
    "    ctab = _wide_cr_settings_clust[\"container\"].data.copy()\n",
    "    ii = ((ctab[magcol] > mag_lims[0]) & (ctab[magcol] < mag_lims[1]) &\n",
    "          (ctab[rcol] > r_lims[0]) & (ctab[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(ctab[ii][col], bins=bins_hist)[0]    \n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"orange\", label=\"Cluster LOS\", lw=2)    \n",
    "\n",
    "    ii = (sample[magcol] > mag_lims[0]) & (sample[magcol] < mag_lims[1])\n",
    "    counts = np.histogram(sample[ii][col], bins=bins_hist)[0]\n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"cornflowerblue\", lw=2, label=\"field\")     \n",
    "    \n",
    "    allsample = allsamples[rbin]\n",
    "    ii = ((allsample[magcol] > mag_lims[0]) & (allsample[magcol] < mag_lims[1]) &\n",
    "          (allsample[rcol] > r_lims[0]) & (allsample[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(allsample[ii][col], bins=bins_kde, density=True)[0]    \n",
    "    ax.plot(cens, counts, ls=\"--\", color=\"black\", lw=2.5, label=\"LOS model\")    \n",
    "    \n",
    "# ####################################################################################################\n",
    "mag_lims = (21., 22.5)\n",
    "for rbin in np.arange(4):\n",
    "    ax = axarr[1, rbin]\n",
    "\n",
    "    r_lims = r_lims_all[rbin]\n",
    "    sample = samples[rbin]\n",
    "    csample = csamples[rbin]\n",
    "    rsample = rsamples[rbin]\n",
    "\n",
    "    ctab = _wide_cr_settings_clust[\"container\"].data.copy()\n",
    "    ii = ((ctab[magcol] > mag_lims[0]) & (ctab[magcol] < mag_lims[1]) &\n",
    "          (ctab[rcol] > r_lims[0]) & (ctab[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(ctab[ii][col], bins=bins_hist)[0]    \n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"orange\", label=\"Cluster LOS\", lw=2)    \n",
    "    \n",
    "    ii = (sample[magcol] > mag_lims[0]) & (sample[magcol] < mag_lims[1])\n",
    "    counts = np.histogram(sample[ii][col], bins=bins_hist)[0]\n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"cornflowerblue\", lw=2, label=\"field\") \n",
    "    \n",
    "    allsample = allsamples[rbin]\n",
    "    ii = ((allsample[magcol] > mag_lims[0]) & (allsample[magcol] < mag_lims[1]) &\n",
    "          (allsample[rcol] > r_lims[0]) & (allsample[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(allsample[ii][col], bins=bins_kde, density=True)[0]    \n",
    "    ax.plot(cens, counts, ls=\"--\", color=\"black\", lw=2.5, label=\"LOS model\")        \n",
    "\n",
    "    \n",
    "# ####################################################################################################\n",
    "mag_lims = (23., 24)\n",
    "for rbin in np.arange(4):\n",
    "    ax = axarr[2, rbin]\n",
    "\n",
    "    r_lims = r_lims_all[rbin]\n",
    "    sample = samples[rbin]\n",
    "    csample = csamples[rbin]\n",
    "    rsample = rsamples[rbin]\n",
    "   \n",
    "    \n",
    "    ctab = _wide_cr_settings_clust[\"container\"].data.copy()\n",
    "    ii = ((ctab[magcol] > mag_lims[0]) & (ctab[magcol] < mag_lims[1]) &\n",
    "          (ctab[rcol] > r_lims[0]) & (ctab[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(ctab[ii][col], bins=bins_hist)[0]    \n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"orange\", label=\"Cluster LOS\", lw=2)    \n",
    "    \n",
    "    ii = (sample[magcol] > mag_lims[0]) & (sample[magcol] < mag_lims[1])\n",
    "    counts = np.histogram(sample[ii][col], bins=bins_hist)[0]\n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"cornflowerblue\", lw=2, label=\"field\")    \n",
    "\n",
    "    allsample = allsamples[rbin]\n",
    "    ii = ((allsample[magcol] > mag_lims[0]) & (allsample[magcol] < mag_lims[1]) &\n",
    "          (allsample[rcol] > r_lims[0]) & (allsample[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(allsample[ii][col], bins=bins_kde, density=True)[0]    \n",
    "    ax.plot(cens, counts, ls=\"--\", color=\"black\", lw=2.5, label=\"LOS model\")     \n",
    "    handles, labels = ax.get_legend_handles_labels()    \n",
    "\n",
    "    \n",
    "fs = 10\n",
    "\n",
    "axarr[2, 3].legend(loc=1, fontsize=fs, handles=handles, labels=labels)    \n",
    "# axarr[2, 2].legend(loc=1, fontsize=fs, handles=handles[3:], labels=labels[3:])  \n",
    "    \n",
    "\n",
    "# axarr[2, 0].text(0.05, 0.72, \"Depth Extrapolation\", transform=axarr[2, 0].transAxes, fontsize=fs)\n",
    "axarr[0, 0].text(0.05, 0.63, \"$\\lambda\\in[30;\\,60)$\", transform=axarr[0, 0].transAxes, fontsize=fs)\n",
    "axarr[0, 0].text(0.05, 0.51, \"$z\\in[0.3;\\,0.35)$\", transform=axarr[0, 0].transAxes, fontsize=fs)\n",
    "\n",
    "axarr[0, 0].text(0.05, 0.85, \"$i-mag\\in[19;\\, 21]$\", transform=axarr[0, 0].transAxes, fontsize=fs)\n",
    "axarr[1, 0].text(0.05, 0.85, \"$i-mag\\in[21;\\, 22.5]$\", transform=axarr[1, 0].transAxes, fontsize=fs)\n",
    "axarr[2, 0].text(0.05, 0.85, \"$i-mag\\in[23;\\, 24]$ \", transform=axarr[2, 0].transAxes, fontsize=fs)\n",
    "axarr[2, 0].text(0.05, 0.73, \"Depth Extrapolation\".upper(), transform=axarr[2, 0].transAxes, fontsize=fs, color=\"red\")\n",
    "fig.text(0.13, 0.9, \"DC2 redmapper clusters Emulator model\", fontsize=14)\n",
    "# fig.savefig(\"DC2-ALPHA_LOWZ_decoupled_g-r-color_magnitude_slices_radial_v01.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(nrows=3, ncols=4, figsize=(11.5, 7.), sharex=False, sharey=False)\n",
    "fig.subplots_adjust(hspace=0.075, wspace=0.05)\n",
    "\n",
    "bins_hist = np.linspace(4, 12, 20)\n",
    "cens_hist = bins_hist[:-1] + np.diff(bins_hist) / 2\n",
    "bins_kde = np.linspace(4, 12, 40)\n",
    "cens = bins_kde[:-1] + np.diff(bins_kde) / 2\n",
    "\n",
    "for ax in axarr[0]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in axarr[1]:\n",
    "    ax.set_xticklabels([])    \n",
    "\n",
    "for ax in axarr[:, 0]:\n",
    "    ax.set_yticklabels([\"0\", \"1\", \"2\", \"3\", \"\"])\n",
    "    \n",
    "for ax in axarr[0, 1:]:\n",
    "    ax.set_yticklabels([])\n",
    "for ax in axarr[1, 1:]:\n",
    "    ax.set_yticklabels([])\n",
    "for ax in axarr[2, 1:]:\n",
    "    ax.set_yticklabels([])    \n",
    "        \n",
    "for ax in axarr[2]:\n",
    "    ax.set_xlabel(\"stellar mass [Msun]\", fontsize=12)\n",
    "for ax in axarr[:, 0]:\n",
    "    ax.set_ylabel(\"p.d.f.\", fontsize=12)\n",
    "    \n",
    "col = \"STELLAR_MASS\" \n",
    "magcol = \"MAG_I\"\n",
    "rcol = \"LOGR\"\n",
    "\n",
    "r_lims_all = [(-1.5, -0.5), (-0.5, 0.), (0, 0.5), (0.5, 1.0)]\n",
    "\n",
    "# ####################################################################################################\n",
    "mag_lims = (19., 21.)\n",
    "for rbin in np.arange(4):\n",
    "    ax = axarr[0, rbin]\n",
    "\n",
    "    r_lims = r_lims_all[rbin]\n",
    "    sample = samples[rbin]\n",
    "    csample = csamples[rbin]\n",
    "    rsample = rsamples[rbin]\n",
    "    \n",
    "    ctab = _wide_cr_settings_clust[\"container\"].data.copy()\n",
    "    ii = ((ctab[magcol] > mag_lims[0]) & (ctab[magcol] < mag_lims[1]) &\n",
    "          (ctab[rcol] > r_lims[0]) & (ctab[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(ctab[ii][col], bins=bins_hist)[0]    \n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"orange\", label=\"Cluster LOS\", lw=2)    \n",
    "\n",
    "    ii = (sample[magcol] > mag_lims[0]) & (sample[magcol] < mag_lims[1])\n",
    "    counts = np.histogram(sample[ii][col], bins=bins_hist)[0]\n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"cornflowerblue\", lw=2, label=\"field\")         \n",
    "    \n",
    "    allsample = allsamples[rbin]\n",
    "    ii = ((allsample[magcol] > mag_lims[0]) & (allsample[magcol] < mag_lims[1]) &\n",
    "          (allsample[rcol] > r_lims[0]) & (allsample[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(allsample[ii][col], bins=bins_kde, density=True)[0]    \n",
    "    ax.plot(cens, counts, ls=\"--\", color=\"black\", lw=2.5, label=\"LOS model\")    \n",
    "    \n",
    "# ####################################################################################################\n",
    "mag_lims = (21., 22.5)\n",
    "for rbin in np.arange(4):\n",
    "    ax = axarr[1, rbin]\n",
    "\n",
    "    r_lims = r_lims_all[rbin]\n",
    "    sample = samples[rbin]\n",
    "    csample = csamples[rbin]\n",
    "    rsample = rsamples[rbin]\n",
    "\n",
    "    ctab = _wide_cr_settings_clust[\"container\"].data.copy()\n",
    "    ii = ((ctab[magcol] > mag_lims[0]) & (ctab[magcol] < mag_lims[1]) &\n",
    "          (ctab[rcol] > r_lims[0]) & (ctab[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(ctab[ii][col], bins=bins_hist)[0]    \n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"orange\", label=\"Cluster LOS\", lw=2)    \n",
    "    \n",
    "    ii = (sample[magcol] > mag_lims[0]) & (sample[magcol] < mag_lims[1])\n",
    "    counts = np.histogram(sample[ii][col], bins=bins_hist)[0]\n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"cornflowerblue\", lw=2, label=\"field\")     \n",
    "    \n",
    "    allsample = allsamples[rbin]\n",
    "    ii = ((allsample[magcol] > mag_lims[0]) & (allsample[magcol] < mag_lims[1]) &\n",
    "          (allsample[rcol] > r_lims[0]) & (allsample[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(allsample[ii][col], bins=bins_kde, density=True)[0]    \n",
    "    ax.plot(cens, counts, ls=\"--\", color=\"black\", lw=2.5, label=\"LOS model\")        \n",
    "\n",
    "    \n",
    "# ####################################################################################################\n",
    "mag_lims = (23., 24)\n",
    "for rbin in np.arange(4):\n",
    "    ax = axarr[2, rbin]\n",
    "\n",
    "    r_lims = r_lims_all[rbin]\n",
    "    sample = samples[rbin]\n",
    "    csample = csamples[rbin]\n",
    "    rsample = rsamples[rbin]\n",
    "    \n",
    "    \n",
    "    ctab = _wide_cr_settings_clust[\"container\"].data.copy()\n",
    "    ii = ((ctab[magcol] > mag_lims[0]) & (ctab[magcol] < mag_lims[1]) &\n",
    "          (ctab[rcol] > r_lims[0]) & (ctab[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(ctab[ii][col], bins=bins_hist)[0]    \n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"orange\", label=\"Cluster LOS\", lw=2)    \n",
    "    \n",
    "    ii = (sample[magcol] > mag_lims[0]) & (sample[magcol] < mag_lims[1])\n",
    "    counts = np.histogram(sample[ii][col], bins=bins_hist)[0]\n",
    "    c16 = (counts - np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    c84 = (counts + np.sqrt(counts)) / (counts * np.diff(bins_hist)).sum()\n",
    "    counts = counts / (counts * np.diff(bins_hist)).sum()\n",
    "    edges, v16 = tohist(bins_hist, c16)\n",
    "    edges, v84 = tohist(bins_hist, c84)\n",
    "    ax.fill_between(edges, v16, v84, color=\"cornflowerblue\", lw=2, label=\"field\")     \n",
    "    \n",
    "    allsample = allsamples[rbin]\n",
    "    ii = ((allsample[magcol] > mag_lims[0]) & (allsample[magcol] < mag_lims[1]) &\n",
    "          (allsample[rcol] > r_lims[0]) & (allsample[rcol] < r_lims[1]))\n",
    "    counts = np.histogram(allsample[ii][col], bins=bins_kde, density=True)[0]    \n",
    "    ax.plot(cens, counts, ls=\"--\", color=\"black\", lw=2.5, label=\"LOS model\")     \n",
    "    handles, labels = ax.get_legend_handles_labels()    \n",
    "\n",
    "    \n",
    "fs = 10\n",
    "\n",
    "axarr[2, 3].legend(loc=3, fontsize=fs, handles=handles, labels=labels)    \n",
    "# axarr[2, 2].legend(loc=1, fontsize=fs, handles=handles[3:], labels=labels[3:])  \n",
    "    \n",
    "\n",
    "# axarr[2, 0].text(0.05, 0.72, \"Depth Extrapolation\", transform=axarr[2, 0].transAxes, fontsize=fs)\n",
    "axarr[0, 0].text(0.05, 0.63, \"$\\lambda\\in[30;\\,60)$\", transform=axarr[0, 0].transAxes, fontsize=fs)\n",
    "axarr[0, 0].text(0.05, 0.51, \"$z\\in[0.3;\\,0.35)$\", transform=axarr[0, 0].transAxes, fontsize=fs)\n",
    "\n",
    "axarr[0, 0].text(0.05, 0.85, \"$i-mag\\in[19;\\, 21]$\", transform=axarr[0, 0].transAxes, fontsize=fs)\n",
    "axarr[1, 0].text(0.05, 0.85, \"$i-mag\\in[21;\\, 22.5]$\", transform=axarr[1, 0].transAxes, fontsize=fs)\n",
    "axarr[2, 0].text(0.05, 0.85, \"$i-mag\\in[23;\\, 24]$ \", transform=axarr[2, 0].transAxes, fontsize=fs)\n",
    "axarr[0, 3].text(0.45, 0.73, \"Extrapolation\".upper(), transform=axarr[0, 3].transAxes, fontsize=fs, color=\"red\")\n",
    "axarr[1, 3].text(0.45, 0.73, \"Extrapolation\".upper(), transform=axarr[1, 3].transAxes, fontsize=fs, color=\"red\")\n",
    "axarr[2, 3].text(0.45, 0.73, \"Extrapolation\".upper(), transform=axarr[2, 3].transAxes, fontsize=fs, color=\"red\")\n",
    "fig.text(0.13, 0.9, \"DC2 redmapper clusters Emulator model\", fontsize=14)\n",
    "# fig.savefig(\"DC2-ALPHA_LOWZ_decoupled_size_magnitude_slices_radial_v01.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
